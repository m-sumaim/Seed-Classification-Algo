{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjvUTZMn9iiX"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/m-sumaim/corn_seed_dataset/archive/refs/heads/main.zip\" \\\n",
        "    -O \"/tmp/seed_class.zip\"\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/tmp/seed_class.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "spodQCMv__u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "#from PIL import Image as image\n",
        "import numpy as np\n",
        "\n",
        "# Set the directories for the training and testing data\n",
        "train_dir = '/tmp/corn_seed_dataset-main/train'\n",
        "test_dir = '/tmp/corn_seed_dataset-main/validation'\n",
        "\n",
        "# Create an ImageDataGenerator for the training data with data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# Create an ImageDataGenerator for the testing data without data augmentation\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create a train generator that generates batches of augmented images from the training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Create a test generator that generates batches of images from the testing data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Build the CNN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=5,\n",
        "                    validation_data=test_generator)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('corn_seed_classifier.h5')\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('corn_seed_classifier.h5')\n",
        "\n",
        "def predict_image(image_path):\n",
        "    # Load the image and resize it to the required size\n",
        "    img = image.load_img(image_path, target_size=(150, 150))\n",
        "\n",
        "    # Convert the image to a numpy array and normalize it\n",
        "    x = image.img_to_array(img)\n",
        "    x = x / 255.0\n",
        "\n",
        "    # Add a new axis to create a batch of size 1\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    # Make a prediction on the image\n",
        "    predictions = model.predict(x)\n",
        "\n",
        "    # Get the index of the class with the highest probability\n",
        "    class_index = np.argmax(predictions[0])\n",
        "\n",
        "    # Get the name of the class from the class index\n",
        "    class_names = ['Broken', 'Discolored', 'Pure', 'Silkcut']\n",
        "    predicted_class_name = class_names[class_index]\n",
        "\n",
        "    # Get the probability of the predicted class\n",
        "    class_probability = predictions[0][class_index]\n",
        "\n",
        "    return predicted_class_name, class_probability\n",
        "\n",
        "# Make a prediction on the image\n",
        "image_path = '/home/test_image.png'\n",
        "predicted_class_name, class_probability = predict_image(image_path)\n",
        "\n",
        "# Print the predicted class and its probability\n",
        "print(f'The predicted class is: {predicted_class_name}')\n",
        "print(f'The probability of the predicted class is: {class_probability:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeaZinqrBxO5",
        "outputId": "33efd8f7-ae6a-4e42-ab78-f6bc0808803f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14327 images belonging to 4 classes.\n",
            "Found 3474 images belonging to 4 classes.\n",
            "Epoch 1/5\n",
            "322/448 [====================>.........] - ETA: 4:20 - loss: 1.2715 - accuracy: 0.4030"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction on the image\n",
        "image_path = '/home/broken_test.png'\n",
        "predicted_class_name, class_probability = predict_image(image_path)\n",
        "\n",
        "# Print the predicted class and its probability\n",
        "print(f'The predicted class is: {predicted_class_name}')\n",
        "print(f'The probability of the predicted class is: {class_probability:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4oe4IqcH2Ku",
        "outputId": "de0d72a7-7cef-4de2-aef6-dcf2705d3d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 42ms/step\n",
            "The predicted class is: Pure\n",
            "The probability of the predicted class is: 0.36\n"
          ]
        }
      ]
    }
  ]
}